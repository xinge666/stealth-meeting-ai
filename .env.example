# ── 1. LLM API Configuration ──────────────────────────────
# Primary model for deep answering
LLM_API_KEY=sk-your-key-here
LLM_BASE_URL=https://api.deepseek.com/v1
LLM_MODEL=deepseek-chat

# Flash model for fast intent routing/filtering
# This model should preferably be fast and cheap (e.g. gpt-4o-mini, qwen-turbo)
LLM_FLASH_API_KEY=sk-your-flash-key-here
LLM_FLASH_BASE_URL=https://api.openai.com/v1
LLM_FLASH_MODEL=gpt-4o-mini

# ── 2. Audio & ASR Configuration ──────────────────────────
# engine_type: "whisper", "qwen_api", or "qwen_local"
ASR_ENGINE=whisper
AUDIO_DEVICE=BlackHole
WHISPER_MODEL=small

# If using qwen_api (DashScope)
QWEN_API_KEY=
QWEN_API_MODEL=sensevoice-v1

# If using qwen_local
QWEN_LOCAL_MODEL_PATH=Qwen/Qwen3-ASR-1.7B
QWEN_LOCAL_DEVICE=cuda

# ── 3. Vision & OCR Configuration ─────────────────────────
# engine_type: "ocr"
VISION_ENGINE=ocr
SCREEN_CAPTURE_INTERVAL=1.5
SCREEN_DIFF_THRESHOLD=0.05

# ── 4. Server Configuration ───────────────────────────────
SERVER_HOST=0.0.0.0
SERVER_PORT=8765
